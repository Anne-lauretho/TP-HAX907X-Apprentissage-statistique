---
format:
  html:
    title-block: false
    toc: false   
---
<!-- Page de garde -->
<div style="display:flex; flex-direction:column; justify-content:center; align-items:center; height:100vh; text-align:center; font-family:Arial, sans-serif;">

<h1 style="font-size:3em; margin-bottom:0.5em;">TP : Support Vector Machines</h1>

<hr style="width:50%; margin:1em 0;">

<h3>Réalisé par :</h3>
<p><strong>STETSUN Kateryna</strong><br>
<strong>THOMAS Anne-Laure</strong></p>

<p style="margin-top:2em;">Date : <span id="today"></span></p>

</div>

<script>
  // insère la date automatiquement en français
  document.getElementById("today").textContent = new Date().toLocaleDateString("fr-FR");
</script>

<div style="page-break-after: always;"></div>

# Introduction

Les machines à vecteurs de support (SVM), introduites par Vapnik dans les années 1990, sont devenues l'une des méthodes de classification supervisée les plus populaires. Leur succès s'explique par leur capacité à construire des règles de décision linéaires, appelées hyperplans séparateurs, tout en permettant d'aborder des problèmes où les données ne sont pas directement séparables dans l'espace d'entrée.

Le principe des SVM repose sur la recherche d'un hyperplan qui maximise la marge entre les classes. Dans le cas linéaire, cet hyperplan est directement construit dans l'espace des variables initiales. Dans les cas plus complexes, une transformation implicite des données dans un espace de dimension supérieure est effectuée grâce au `kernel trick`. Cette astuce permet de manipuler uniquement les produits scalaires dans l'espace transformé, en utilisant une fonction noyau. Parmi les noyaux courants, on retrouve le noyau linéaire, le noyau polynomial, le noyau gaussien RBF ou encore le noyau sigmoïde.

L'apprentissage consiste alors à résoudre un problème d'optimisation sous contraintes, dans lequel un paramètre de régularisation, noté `C`, contrôle la complexité du modèle et le compromis entre maximisation de la marge et minimisation des erreurs de classification.

L'objectif de ce TP est de mettre en pratique ces concepts à travers différents jeux de données, simulés et réels. Nous utiliserons pour cela la bibliothèque `scikit-learn`, qui propose une implémentation performante des SVM via la librairie libsvm.

# Mise en oeuvre

## 1. Jeu de données jouet (deux gaussiennes)

Pour commencer, ...

```{python}

```

## 2. Comparaison du résultat avec un SVM basé sur noyau polynomial

# Classification de visages

## 4.

## 5.

## 6.

## 7.
